{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4bd35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from numpy import fft\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy import signal\n",
    "from scipy.signal import filtfilt\n",
    "from scipy.fft import fft, fftfreq    \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt   \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ba035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from folders\n",
    "fs = 173.61\n",
    "\n",
    "def load_data(folders):\n",
    "    data = {}\n",
    "    \n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join('E:\\EEG Signal Processing\\EEG-Signal-Processing\\Dataset', folder)\n",
    "        files = os.listdir(folder_path)\n",
    "        matrix = []\n",
    "    \n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            matrix.append(np.loadtxt(file_path))\n",
    "        \n",
    "        data[folder] = np.array(matrix)\n",
    "    \n",
    "    return data\n",
    "\n",
    "folders = ['F', 'N', 'O', 'S', 'Z']\n",
    "data = load_data(folders)\n",
    "\n",
    "F = data['F']\n",
    "N = data['N']\n",
    "O = data['O']\n",
    "S = data['S']\n",
    "Z = data['Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60060255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bandstop(sig):\n",
    "    # Design stop filter\n",
    "    fl = 49.9\n",
    "    fh = 50.1\n",
    "    order = 3\n",
    "    ftype = 'bandstop'\n",
    "    b, a = signal.butter(order, [fl, fh], ftype, fs=fs)\n",
    "    Sig = signal.filtfilt(b, a, sig)\n",
    "    return Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f47e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BandExt(Sig, fs):\n",
    "\n",
    "    # bandpass butterworth filter\n",
    "    Band = np.array([[0.1, 4, 8, 12, 30],\n",
    "                     [4, 8, 12, 30, 70]])\n",
    "    sigf = []\n",
    "    Delta = []\n",
    "    Theta = []\n",
    "    Beta = []\n",
    "    Alpha = []\n",
    "    Gamma = []\n",
    "    TBands = []\n",
    "    \n",
    "    for k in range(5):\n",
    "        fl = Band[0][k]\n",
    "        fh = Band[1][k]\n",
    "        order = 3\n",
    "        wn = [fl, fh]\n",
    "        ftype = 'bandpass'\n",
    "        b, a = signal.butter(order, wn, ftype, fs=fs)\n",
    "        # apply designed filter\n",
    "        sig_f = signal.filtfilt(b, a, Sig)\n",
    "        sigf.append(sig_f)\n",
    "    Delta = sigf[0]\n",
    "    Theta = sigf[1]\n",
    "    Alpha = sigf[2]\n",
    "    Beta = sigf[3]\n",
    "    Gamma = sigf[4]\n",
    "    \n",
    "    return sigf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d952bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetFFT(Sig, fs):\n",
    "    \n",
    "    sig_fft = np.fft.fft(Sig)\n",
    "    sig_fft = np.abs(sig_fft)          \n",
    "\n",
    "    # Get the signal duration\n",
    "    \n",
    "    sig_len = len(Sig)\n",
    "    fft_freq = np.fft.fftfreq(sig_len,1/fs)\n",
    "\n",
    "    # Remove the first half\n",
    "\n",
    "    sig_fft = sig_fft[:sig_len//2]\n",
    "    fft_freq = fft_freq[:sig_len//2]\n",
    "\n",
    "\n",
    "    return sig_fft, fft_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36de296",
   "metadata": {},
   "outputs": [],
   "source": [
    " Band = np.array([[0.1, 4, 8, 12, 30],\n",
    "                  [4, 8, 12, 30, 70]])\n",
    "def GetBfft(Sig, fs, Band):\n",
    "\n",
    "    band = []\n",
    "    bands = []\n",
    "    all_bands = []\n",
    "    sig, rf = GetFFT(Sig, fs)\n",
    "    \n",
    "\n",
    "    for k in range(Band.shape[1]):\n",
    "        fll = Band[0][k]\n",
    "        fhh = Band[1][k]\n",
    "        indx = np.where((rf >= fll) & (rf<fhh))\n",
    "        band = sig[indx]\n",
    "        bands.append(band)\n",
    "   \n",
    "\n",
    "    return bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0058ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetWavelet(Sig, Wavelet, Level):\n",
    "\n",
    "    # Wavelet Decomposition with the Given Properties\n",
    "    WaveDec = pywt.wavedec(Sig, Wavelet, level=Level)\n",
    "    \n",
    "    return WaveDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd2dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def STFT(Sig, fs, window_size, overlap):\n",
    "    sig_len = len(Sig)\n",
    "    window = np.hamming(window_size)\n",
    "    num_frames = int(np.ceil(sig_len / (window_size - overlap)))\n",
    "    stft = np.zeros((window_size, num_frames), dtype=complex)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        start = i * (window_size - overlap)\n",
    "        end = min(start + window_size, sig_len)\n",
    "        frame = Sig[start:end]\n",
    "        frame *= window[:end-start]\n",
    "        stft[:end-start, i] = np.fft.fft(frame)\n",
    "    \n",
    "    stft = np.abs(stft)\n",
    "    stft = stft[:window_size//2, :]\n",
    "    \n",
    "    freq = np.fft.fftfreq(window_size, 1/fs)[:window_size//2]\n",
    "    \n",
    "    return stft, freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cba3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfeatureExtraction(Sig):\n",
    "\n",
    "    Mean   = np.mean(Sig)              \n",
    "    \n",
    "    Var = np.var(Sig)\n",
    "    \n",
    "    Power= np.mean(np.square(Sig))\n",
    "    \n",
    "    std = np.std(Sig)\n",
    "     # Check if standard deviation is zero\n",
    "    if std == 0:\n",
    "        Skew = 0.0\n",
    "        kurt = 0.0\n",
    "    else:\n",
    "        # Compute skewness\n",
    "        Skew = np.sum(((Sig - Mean) / std) ** 3) / len(Sig)\n",
    "\n",
    "        # Compute kurtosis\n",
    "        kurt =  np.sum(((Sig - Mean) / std) ** 4) / len(Sig) - 3\n",
    "\n",
    "    Ent = np.sum(np.power(Sig, 2) * np.log(np.power(Sig, 2)+0.0001))\n",
    "    \n",
    "    return np.array([Mean ,Var, Power, kurt, Skew, Ent]).reshape(1, -1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1801c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 126)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "F_df = pd.DataFrame(F)\n",
    "N_df = pd.DataFrame(N)\n",
    "O_df = pd.DataFrame(O)\n",
    "S_df = pd.DataFrame(S)\n",
    "Z_df = pd.DataFrame(Z)\n",
    "\n",
    "Data = pd.concat([F_df, N_df, O_df, S_df, Z_df], axis=0, ignore_index=True).to_numpy()\n",
    "\n",
    "# Create a dictionary to store the feature vectors for each subdata\n",
    "features_dict = {'F': [], 'N': [], 'O': [], 'S': [], 'Z': []}\n",
    "\n",
    "# Create a dictionary to store the extracted bands for each subdata\n",
    "bands_dict = {'F': [], 'N': [], 'O': [], 'S': [], 'Z': []}\n",
    "\n",
    "Totaldata = pd.DataFrame()\n",
    "label = pd.DataFrame()\n",
    "\n",
    "# Iterate over subdata\n",
    "for subdata_name, subdata in zip(['F', 'N', 'O', 'S', 'Z'], [F, N, O, S, Z]):\n",
    "    \n",
    "    # Iterate over rows of subdata\n",
    "    for Signal in subdata:\n",
    "        Signal = Bandstop(Signal)\n",
    "        \n",
    "        # Signal Rhythmic Extraction\n",
    "        rhythms  = BandExt(Signal, fs)\n",
    "        \n",
    "        feature_vector = np.array([])\n",
    "        \n",
    "        for rhythm in rhythms:\n",
    "            \n",
    "            # Time domain feature extraction\n",
    "            feature_vector = np.append(feature_vector, myfeatureExtraction(rhythm))\n",
    "            \n",
    "            # FFT domain feature extraction\n",
    "            fft, _ = GetFFT(rhythm, fs)\n",
    "            feature_vector =  np.append(feature_vector, myfeatureExtraction(fft))\n",
    "            \n",
    "        # STFT domain features extraction and append to feature vector\n",
    "        window_size = 256\n",
    "        overlap = 128\n",
    "        Band = np.array([[0.1, 4, 8, 12, 30], [4, 8, 12, 30, 70]])\n",
    "        \n",
    "        stft, freq = STFT(Signal, fs, window_size, overlap)\n",
    "        \n",
    "        for i in range(Band.shape[1]):\n",
    "            low_freq = Band[0, i]\n",
    "            high_freq = Band[1, i]\n",
    "            mask = (freq >= low_freq) & (freq <= high_freq)\n",
    "            band_stft = stft[mask, :]\n",
    "        \n",
    "            feature_vector = np.append(feature_vector, myfeatureExtraction(stft))\n",
    "        \n",
    "        # Wavelet domain features extraction and append to feature vector\n",
    "        wave_dec = GetWavelet(Signal, 'db6', 5)\n",
    "\n",
    "        for wave in wave_dec:\n",
    "            feature_vector = np.append(feature_vector, myfeatureExtraction(wave))\n",
    "            \n",
    "        # Reshape the feature vector into a single column and concatenate to the features dataframe\n",
    "        Totaldata = pd.concat([Totaldata, pd.DataFrame(feature_vector.reshape(1, -1))], axis=0, ignore_index=True)\n",
    "        \n",
    "        if subdata_name == 'Z' or subdata_name == 'O':       # Normal\n",
    "            label = np.append(label, 0)\n",
    "        \n",
    "        elif subdata_name == 'N' or subdata_name == 'F':     # Epileptic\n",
    "            label = np.append(label, 1)\n",
    "            \n",
    "        elif subdata_name == 'S':                            # Epilepsy-Seizure\n",
    "            label = np.append(label, 2)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "print(Totaldata.shape)\n",
    "print(label.shape)\n",
    "\n",
    "Totaldata = np.array(Totaldata)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e2a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatrain, datatest, dtrain, dtest = train_test_split(Totaldata, label, test_size=0.3, shuffle=True)\n",
    "\n",
    "# # K nearest Neighbors Parameter \n",
    "# K = 5\n",
    "\n",
    "# # Feature selection\n",
    "# indx_f = np.arange(datatrain.shape[1])\n",
    "# sel = []\n",
    "# max_numf = 30\n",
    "# bestperfomance = []\n",
    "\n",
    "# for iter in range(1, max_numf+1):\n",
    "#     perfomance = np.zeros(len(indx_f))\n",
    "#     c = 0\n",
    "    \n",
    "#     for indx in (indx_f):\n",
    "#         c += 1\n",
    "#         indx_cond = np.concatenate((sel, [indx])).astype(int)\n",
    "        \n",
    "#         # print(indx_cond)\n",
    "        \n",
    "#         datatrain_cond = datatrain[:, indx_cond]\n",
    "#         datatest_cond = datatest[:, indx_cond]\n",
    "        \n",
    "#         # Train classifier\n",
    "#         mdl = KNeighborsClassifier(n_neighbors=K, n_jobs=4, algorithm='auto', weights='distance')\n",
    "\n",
    "#         mdl.fit(datatrain_cond, dtrain)\n",
    "        \n",
    "#         # Test trained classifier\n",
    "#         output = mdl.predict(datatest_cond)\n",
    "        \n",
    "#         # Validation\n",
    "#         Cmat = confusion_matrix(dtest, output)\n",
    "#         accuracy = np.sum(np.diag(Cmat)) / np.sum(Cmat) * 100\n",
    "        \n",
    "#         perfomance[c-1] = accuracy\n",
    "        \n",
    "# #     print(\"select \", sel, \" perform : \", perfomance)\n",
    "        \n",
    "#     ind = np.argmax(perfomance)\n",
    "#     print(ind)\n",
    "#     bestperfomance.append(perfomance[ind])\n",
    "#     sel.append(indx_f[ind])\n",
    "    \n",
    "#     print(\"Best Feature \", np.argmax(perfomance), \" performance\", np.max(perfomance), \" sel \", sel)\n",
    "\n",
    "#     indx_f = np.delete(indx_f, ind)\n",
    "#     #print(ind)\n",
    "       \n",
    "\n",
    "# sel = np.array(sel)\n",
    "# bestperfomance = np.array(bestperfomance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58efd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Selected Features : \", sel)\n",
    "\n",
    "# datatrain = datatrain[:, sel]\n",
    "# datatest = datatest[:, sel]\n",
    "\n",
    "# print(\"Train data size: \", datatrain.shape)\n",
    "# print(\"Test data size: \", datatest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba24eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train classifier\n",
    "# K = 7\n",
    "# mdl = KNeighborsClassifier(n_neighbors=K, n_jobs=4, algorithm='auto', weights='distance')\n",
    "\n",
    "# mdl.fit(datatrain_cond, dtrain)\n",
    "\n",
    "# # Test trained classifier\n",
    "# output = mdl.predict(datatest_cond)\n",
    "\n",
    "# # Validation\n",
    "# Cmat = confusion_matrix(dtest, output)\n",
    "# accuracy = np.sum(np.diag(Cmat)) / np.sum(Cmat) * 100\n",
    "\n",
    "# print(\"Confusion Matrix = \\n\", Cmat)\n",
    "# print(\"\\n >>>> Final Model Accuracy = \", accuracy, \"\\n\")\n",
    "\n",
    "# for i in range(Cmat.shape[0]):\n",
    "#     print(f\"Class {i+1} Accuracy  = \", Cmat[i, i] / np.sum(Cmat[i, :]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee658550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best performance  0.8266666666666667 Best Features  [43]\n",
      " best performance  0.94 Best Features  [43, 20]\n",
      " best performance  0.96 Best Features  [43, 20, 101]\n",
      " best performance  0.9666666666666667 Best Features  [43, 20, 101, 53]\n",
      " best performance  0.9666666666666667 Best Features  [43, 20, 101, 53, 0]\n",
      " best performance  0.9666666666666667 Best Features  [43, 20, 101, 53, 0, 1]\n",
      " best performance  0.9666666666666667 Best Features  [43, 20, 101, 53, 0, 1, 2]\n",
      " best performance  0.9666666666666667 Best Features  [43, 20, 101, 53, 0, 1, 2, 3]\n",
      " best performance  0.9666666666666667 Best Features  [43, 20, 101, 53, 0, 1, 2, 3, 4]\n",
      " best performance  0.9666666666666667 Best Features  [43, 20, 101, 53, 0, 1, 2, 3, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "datatrain, datatest, dtrain, dtest = train_test_split(Totaldata, label, test_size=0.3, shuffle=True)\n",
    "\n",
    "num_f = np.arange(datatrain.shape[1])\n",
    "selected = []\n",
    "max_f = 10\n",
    "\n",
    "for i in range(max_f):\n",
    "    perform = []\n",
    "    \n",
    "    for j in num_f:\n",
    "        idx = selected + [j]\n",
    "        \n",
    "        mdl = KNeighborsClassifier(n_neighbors=6, n_jobs=-1, algorithm='auto')\n",
    "        \n",
    "        mdl.fit(datatrain[:, idx], dtrain)\n",
    "        \n",
    "        output = mdl.predict(datatest[:, idx])\n",
    "        \n",
    "        perform.append(accuracy_score(dtest, output))\n",
    "    \n",
    "    bestFeature = np.argmax(perform)\n",
    "    selected.append(num_f[bestFeature])\n",
    "    \n",
    "    print(\" best performance \", np.max(perform), \"Best Features \", selected)\n",
    "    \n",
    "    num_f = np.delete(num_f, bestFeature)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aacbd2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features :  [43, 19, 101, 107, 0, 1, 2, 3, 4, 6]\n",
      "Train data size:  (350, 10)\n",
      "Test data size:  (150, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected Features : \", selected)\n",
    "\n",
    "datatrain = datatrain[:, selected]\n",
    "datatest = datatest[:, selected]\n",
    "\n",
    "print(\"Train data size: \", datatrain.shape)\n",
    "print(\"Test data size: \", datatest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b2c72cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix = \n",
      " [[59  1  0]\n",
      " [ 0 69  0]\n",
      " [ 0  2 19]]\n",
      "\n",
      " >>>> Final Model Accuracy =  98.0 \n",
      "\n",
      "Class 1 Accuracy  =  98.33333333333333\n",
      "Class 2 Accuracy  =  100.0\n",
      "Class 3 Accuracy  =  90.47619047619048\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "K = 7\n",
    "mdl = KNeighborsClassifier(n_neighbors=K, n_jobs=-1, algorithm='auto', weights='distance')\n",
    "\n",
    "mdl.fit(datatrain, dtrain)\n",
    "\n",
    "# Test trained classifier\n",
    "output = mdl.predict(datatest)\n",
    "\n",
    "# Validation\n",
    "Cmat = confusion_matrix(dtest, output)\n",
    "accuracy = np.sum(np.diag(Cmat)) / np.sum(Cmat) * 100\n",
    "\n",
    "print(\"Confusion Matrix = \\n\", Cmat)\n",
    "print(\"\\n >>>> Final Model Accuracy = \", accuracy, \"\\n\")\n",
    "\n",
    "for i in range(Cmat.shape[0]):\n",
    "    print(f\"Class {i+1} Accuracy  = \", Cmat[i, i] / np.sum(Cmat[i, :]) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
